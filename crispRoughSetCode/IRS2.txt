import numpy as np
import copy
class I_RS:## incremental tolerance fuzzy tough set
    def __init__(self):## the use of this tolerance still not decide yet
        pass
    
    def dis_matrix(self):
#############################################################
#step 1: create an empty matrix
        dis_mat = []
        for i in range(self.X.shape[0]):
            row = []
            for j in range(self.X.shape[0]):
                row.append([])
            dis_mat.append(row)
##############################################################
#step 2: for each entry in the matrix, add those attrbute are disimilar more than m_f(id1)
        for id1 in range(self.X.shape[0]-1):
            for id2 in range(id1+1,self.X.shape[0]):
                dis_set = []
                if self.Y[id1] != self.Y[id2]:
                    for attr_id in range(self.X.shape[1]):
                        if self.X[id1,attr_id] != self.X[id2,attr_id]:# left side euqal to 0 or 1 and right side equal to 0 or 1, since it is a crisp rough set 
                            dis_set.append(attr_id)## if so append
                    dis_mat[id1][id2] = dis_set## set it in the matrix
                    dis_mat[id1][id2] = dis_set
        return dis_mat

# this method use the discernibility matrix to find : for each attribute, the pair of object is disimilar(regard to first object's membership degree)    
    def discernibility(self):
        dis_dict = {}## create a dictionary
        for attr_id in list(range(self.X.shape[1])):#initial all the attribute with an empty set, the set will stor the pair
            dis_dict[attr_id] = set()
        dis_mat = self.dis_matrix()       
        for row in range(1,len(dis_mat)-1):#iterate over the discernibility matrix
            for col in range(row,len(dis_mat)):
                for attr in dis_mat[row][col]:
                    dis_dict[attr].add((row,col))#add the pair
        return dis_dict  
    
#this method find the reduct of the initial dataset        
    def find_reduct(self):
##################################################################
# step 1: calculate the discernibility set [(x1,x2)] for each attribute and the combination of each attribute
#         the discernibility of the combination set of all the attribute is the union of discernibility of each attributes
        self.dis_dict = self.discernibility()
        self.dis_all = set()## since it is a set, add duplicate to it will get ignore
        for key in self.dis_dict:
            for pair in self.dis_dict[key]:
                self.dis_all.add(pair)
#################################################################
# step 2: calculate the core of the initial dataset
# we do this by calculate the discernibility of A - a for all a belong A (A denote the combination of all attribute and a is the attributes in A)
# then if there is an 'a' such that dis(A - a) != dis(A), a should be the in the core
        core = []
        for attr_id in list(range(self.X.shape[1])):
            dis_exclude_a = set() #calculate the discernibility of A - a for all a belong A
            for key in self.dis_dict:
                if key == attr_id:
                    continue
                else:
                    dis_exclude_a = dis_exclude_a.union(self.dis_dict[key])
            if dis_exclude_a != self.dis_all:#dis(A - a) != dis(A)
                core.append(attr_id) #a should be the in the core   
#################################################################
# step 3, calculate the reduct
# initialize the reduct with core, calculate the dis(reduct) and for the discenibility set of each attribute, exclude those in the dis(reduct) 
# then iteratively select the attibute with highest discernibility(that is the discernibility set have more element)
# until we get the reduct (hill climbing)
        red = core#initialize the reduct with core
        self.dis_red = set()

        for attr_id in red: #calculate the dis(reduct)
            self.dis_red = self.dis_red.union(self.dis_dict[attr_id])           
        #for the discenibility set of each attribute, exclude those in the dis(reduct)  
        copy_dis_dict = self.dis_dict.copy()
        for attr_id in list(range(self.X.shape[1])):
            if not attr_id in red:
                copy_dis_dict[attr_id] = copy_dis_dict[attr_id].difference(self.dis_red)
# then iteratively select the attibute with highest discernibility(that is the discernibility set have more element)
# until we get the reduct (hill climbing)                
        while self.dis_all != self.dis_red:
            max_size = -1
            candidate = -1
            for attr_id in list(range(self.X.shape[1])):
                if not attr_id in red:
                    if len(copy_dis_dict[attr_id]) > max_size:
                        max_size = len(copy_dis_dict[attr_id])
                        candidate = attr_id
            red.append(candidate)
            self.dis_red = self.dis_red.union(copy_dis_dict[candidate])
            for attr_id in list(range(self.X.shape[1])):
                if not attr_id in red:
                    copy_dis_dict[attr_id] = copy_dis_dict[attr_id].difference(self.dis_red)
        
        return red
    def size(self):
        return self.X.shape[0]
    def fit(self, X, Y):
        self.Y = Y
        self.X = X
        self.rule_miner = LEM2()
        self.reduct_attr = self.find_reduct()
        self.calculate_UX_UR()
        self.calculate_upper_lower()        
        fix_rule,possible_rule = self.rule_miner.induce_rule(self.X,self.Y,self.reduct_attr,self.all_lower_records,self.all_bound_records)
        self.fix_rule = self.find_rule_coverage(fix_rule)
        self.possible_rule = self.find_rule_coverage(possible_rule)

# this method update the reduct when there is new object getting in
# note the new object already added into the self.X, access it by self.X[-1]
# step 1 this method initialize the new reduct by the current reduct, then calculate the dis(new_reduct)
# note that once object getting in, discernibility of each attribute will changed, the method that change them is in next method
# now check if dis_red = dis_all, (note the dis_all is also get changed already in the next method)
# step 2 if dis(new_red) == dis_all go step 4
# step 3 if dis(new_red) != dis_all
#        like what we do before, find the attribute with highest discernibility add it to reduct, until we get dis(new_red) == dis_all
# step 4 then new_red could be a reduct or superset of reduct, need to check whether there is redundant attribute
#        we will check whether there is attribute get deleted, and the rest attributes is still a reduct, if so, delete this attribute
#        keep doing this until there is no such attribute, we get the new reduct
    def update_reduct(self):
#########################################################
# step 1 if dis(new_red) == dis_all go step 4
        if self.dis_red != self.dis_all:
#########################################################
# step 3 like what we do before, find the attribute with highest discernibility add it to reduct, until we get dis(new_red) == dis_all
            while self.dis_red != self.dis_all:
                dis_union_all = {}
                for attr_id in range(self.X.shape[1]):
                    if not attr_id in self.reduct_attr:
                        dis_union_a = self.dis_red.union(self.dis_dict[attr_id])
                        dis_union_all[attr_id] = dis_union_a
                max_key = -1
                max_cover = 0
                for key in dis_union_all:
                    cover = len(dis_union_all[key])
                    if cover > max_cover:
                        max_cover = cover
                        max_key = key
                self.reduct_attr.append(max_key)
                self.dis_red = dis_union_all[max_key]
########################################################
# step 4 new_red could be a reduct or superset of reduct, need to check whether there is redundant attribute               
        while self.dis_red == self.dis_all:
            dis_exclude_all = {}
            #calculate the discernibility after remove one attribute from the new_reduct
            for a in self.reduct_attr:
                dis_exclude_a = set()
                for attr in self.reduct_attr:
                    if attr == a:
                        continue
                    else:
                        dis_exclude_a = dis_exclude_a.union(self.dis_dict[attr])
                dis_exclude_all[a] = dis_exclude_a
            #check whether there is attribute get deleted, and the rest attributes is still a reduct
            candidate_remove = []
            for attr_key in dis_exclude_all:
                if dis_exclude_all[attr_key] == self.dis_all:
                    candidate_remove.append(attr_key)
            if len(candidate_remove) == 0:
                break
            elif len(candidate_remove) > 1:                
                min_key = -1
                min_cover = np.inf
                for i in range(len(candidate_remove)):
                    if len(self.dis_dict[candidate_remove[i]])< min_cover:
                        min_key = candidate_remove[i]
                        min_cover = len(self.dis_dict[candidate_remove[i]])
                self.reduct_attr.remove(min_key)
            else:
                self.reduct_attr.remove(candidate_remove[0])
                                     
    def update(self,newX,newY):#this x should contain the decision as well
        # step0 add the new instance to X and Y
        self.Y = np.append(self.Y,newY)
        self.X = np.row_stack((self.X,newX))                  
        for id1 in range(self.X.shape[0]-1):
            for attr_id in self.dis_dict:
                if self.Y[id1] != self.Y[-1]:
                    if self.X[-1,attr_id] != self.X[id1,attr_id]:
                        self.dis_dict[attr_id].add((id1,self.X.shape[0]-1))
                        self.dis_dict[attr_id].add((self.X.shape[0]-1,id1))
                        self.dis_all.add((id1,self.X.shape[0]-1))
                        self.dis_all.add((self.X.shape[0]-1,id1))
                        if attr_id in self.reduct_attr:
                            self.dis_red.add((id1,self.X.shape[0]-1))
        self.update_reduct()
        self.calculate_UX_UR()
        self.calculate_upper_lower()        
        fix_rule,possible_rule = self.rule_miner.induce_rule(self.X,self.Y,self.reduct_attr,self.all_lower_records,self.all_bound_records)
        self.fix_rule = self.find_rule_coverage(fix_rule)
        self.possible_rule = self.find_rule_coverage(possible_rule)
                
    def update_group(self,newX,newY):
        self.Y = np.append(self.Y,newY)
        self.X = np.row_stack((self.X,newX))
        for id1 in range(self.X.shape[0] - newX.shape[0]):
            for id2 in range(self.X.shape[0] - newX.shape[0], self.X.shape[0]):
                for attr_id in self.dis_dict:
                    if self.Y[id1] != self.Y[id2]:
                        if self.X[id1,attr_id] != self.X[id2,attr_id]:
                            self.dis_dict[attr_id].add((id1,id2))
                            self.dis_all.add((id1,id2))
                            self.dis_dict[attr_id].add((id2,id1))
                            self.dis_all.add((id2,id1))
                            if attr_id in self.reduct_attr:
                                self.dis_red.add((id1,id2))
                                self.dis_red.add((id2,id1))                                
        for attr_id in self.dis_dict:
            for id1 in range(self.X.shape[0] - newX.shape[0], self.X.shape[0]-1):
                for id2 in range(id1, self.X.shape[0]):
                    if self.Y[id1] != self.Y[id2]:
                        if self.X[id1,attr_id] != self.X[id2,attr_id]:
                            self.dis_dict[attr_id].add((id1,id2))
                            self.dis_all.add((id1,id2))
                            self.dis_dict[attr_id].add((id2,id1))
                            self.dis_all.add((id2,id1))
                            if attr_id in self.reduct_attr:
                                self.dis_red.add((id1,id2))
                                self.dis_red.add((id2,id1)) 
        self.update_reduct()
        self.calculate_UX_UR()
        self.calculate_upper_lower()        
        fix_rule,possible_rule = self.rule_miner.induce_rule(self.X,self.Y,self.reduct_attr,self.all_lower_records,self.all_bound_records)
        self.fix_rule = self.find_rule_coverage(fix_rule)
        self.possible_rule = self.find_rule_coverage(possible_rule)
################################################################################################################################
#calculate upper and lower
    def calculate_UX_UR(self):
        values_decision = np.unique(self.Y)
        self.U_X = {}
        for value in values_decision:
            self.U_X[value] = np.where(self.Y == value)[0]
        self.U_R = {}
        for id1 in range(self.X.shape[0]):
            values_conditions = ''
            index_col_name_reduct = 0
            for attr_id in self.reduct_attr:
                values_conditions = values_conditions + str(self.X[id1,attr_id])

                if index_col_name_reduct != len(self.reduct_attr) - 1:
                    values_conditions = values_conditions + ", "

            index_col_name_reduct = index_col_name_reduct + 1
            if not values_conditions in self.U_R:
               self. U_R[values_conditions] = []

            self.U_R[values_conditions].append(id1)   
            
    def calculate_upper_lower(self):
        self.all_bound = {}
        self.all_bound_records = {}
    
        self.all_lower_approximate = {}
        self.all_lower_records = {}
    
        allaR = []
        allBnd = []
    
        for decision in self.U_X:
            lowerap = []
            upperap = []
    
            lowerap_records = set()
            upperap_records = set()
    
            U_Xcon = set(self.U_X[decision])
            for condition in self.U_R:
                U_Rcon = set(self.U_R[condition])
                # if decision is a subset of result
                if (U_Rcon.issubset(U_Xcon)):
                    lowerap.append(condition)
                    lowerap_records = lowerap_records.union(U_Rcon)
                    continue
                # if decision contains element of result
                if (U_Rcon.isdisjoint(U_Xcon) == False):
                    upperap.append(condition)
                    upperap_records = upperap_records.union(U_Rcon)
    
            self.all_lower_approximate[decision] = lowerap
            self.all_lower_records[decision] = lowerap_records
    
            self.all_bound[decision] = upperap
            self.all_bound_records[decision] = upperap_records
    
            # allaR.add(len(lowerap)/len(upperap)) #粗糙度
        # allBnd.append(lowerap - upperap)#bond    
    
    def find_rule_coverage(self,all_rule):
        rule_coverage = []
        for decision in all_rule:
            rules = all_rule[decision]
            for rule in rules:
                cover = set()
                for i in range(self.X.shape[0]):
                    cover.add(i)
                for condition in rule:
                    cover = cover.intersection(set(np.where(self.X[:,condition[0]] == condition[1])[0]))
                match_decision_count = 0
                for id1 in cover:
                    if self.Y[id1] == decision:
                        match_decision_count = match_decision_count+1
                rule_coverage.append((rule,decision,len(cover),match_decision_count/len(cover)))
        return rule_coverage
    
    def predict(self,newX):
        match_decision = {}
        for rule in self.fix_rule:
           condition = rule[0]
           match = True
           for pair in condition:
               if newX[pair[0]] != pair[1]:
                   match = False
                   break
           if match:
               if rule[1] in match_decision:
                   match_decision[rule[1]][0] = match_decision[rule[1]][0]+rule[2]
                   match_decision[rule[1]][1] = match_decision[rule[1]][1]+rule[3]
               else:
                   match_decision[rule[1]] = [rule[2],rule[3]]
        if len(match_decision) == 1:
           for decision in match_decision:
               return decision,match_decision[decision][0]
        elif len(match_decision) > 1:
           max_cover = 0
           final_decision = None
           for decision in match_decision:
               if match_decision[decision][0] > max_cover:
                   max_cover = match_decision[decision][0]
                   final_decision = decision
           return final_decision,max_cover
        elif len(match_decision) == 0:
           #print('Unknow') 
           return 'Unknown',0
       
#    def predict_by_possible_rule(self,newX):
#        match_rule = []
#        for rule in self.possible_rule:
#           condition = rule[0]
#           match = True
#           for pair in condition:
#               if newX[pair[0]] != pair[1]:
#                   match = False
#                   break
#           if match:
#               match_rule.append(rule)
#        if len(match_rule) == 1:
#           return match_rule[0][1],match_rule[0][2]*match_rule[0][3]
#        elif len(match_rule) > 1:
#           max_confidence = 0
#           max_cover = 0
#           final_decision = None
#           for rule in match_rule:
#               if rule[2] > max_confidence:
#                   max_confidence = rule[3]
#                   max_cover = rule[2]
#                   final_decision = rule[1]        
#           return final_decision, max_confidence*max_cover
#        elif len(match_rule) == 0:
#           return self.Y[0],0 
       
                    # -*- coding: utf-8 -*-
   
class LEM2:
    def induce_rule(self,X,Y,reduct,lower_record,upper_record):
        self.all_t = self.get_all_t(X,Y,reduct)
        self.populate_all_t(X,Y,reduct)
        possible_rule = self.lem2(upper_record)
        fix_rule = self.lem2(lower_record)
        return fix_rule,possible_rule
        
    def get_all_t(self,X,Y,reduct):
        all_t = {}
        for attr_id in reduct:
            all_t[attr_id] = {}
            unique_values = np.unique(X[:,attr_id])
            for value in unique_values:
                all_t[attr_id][value] = set()
        return all_t

    def populate_all_t(self,X,Y,reduct):
        for id1 in range(X.shape[0]):
            for attr_id in reduct:
                self.all_t[attr_id][X[id1,attr_id]].add(id1)

    def calculate_all_relevant_T_G(self,G):
        all_relevant_T_G = set()    
        for condition in self.all_t:
            for value in self.all_t[condition]:
                intersection = self.all_t[condition][value].intersection(G)
                if len(intersection) != 0:
                    t = [condition, value]
                    all_relevant_T_G.add(tuple(t))
    
        return all_relevant_T_G


    def get_all_item_in_T(self,T):
        all_set_t = []
        for t in T:
            all_set_t.append(self.all_t[t[0]][t[1]])
    
        all_items_in_T = set()
    
        if len(all_set_t) != 0:
            all_items_in_T = all_set_t[0]
            for t in all_set_t:
                all_items_in_T = all_items_in_T.intersection(t)
    
        return all_items_in_T


    def get_all_item_in_hollow_T(self,hollow_T):
        all_items_in_hollow_T = set()
    
        for T in hollow_T:
            all_items_in_hollow_T = all_items_in_hollow_T.union(self.get_all_item_in_T(T))
    
        return all_items_in_hollow_T


    def delete_t_from_T(self,T, t):
        for pair in T:
            if pair[0] == t[0] and pair[1] == t[1]:
                T.remove(t)
                break


    def equal_two_T(self,T_1, T_2):
        list_T_1 = list(T_1)
        list_T_1.sort()
        list_T_2 = list(T_2)
        list_T_2.sort()    
        return np.array_equal(list_T_1,list_T_2)


    def delete_T_from_hollow_T(self,hollow_T, T_to_delete):
        copy_hollow_T = copy.deepcopy(hollow_T)
        the_T_to_delete = None
    
        for T in copy_hollow_T:
            if self.equal_two_T(T, T_to_delete):
                the_T_to_delete = T
                break
    
        copy_hollow_T.remove(the_T_to_delete)
        return copy_hollow_T

    def select_a_t(self,all_relevant_T_G, G):
        list_all_relevant_T_G = list(all_relevant_T_G)
        list_cardinality = []
    
        index = 0
        while index < len(list_all_relevant_T_G):
            t = list_all_relevant_T_G[index]
            set_t = self.all_t[t[0]][t[1]]
            t_intersect_G = set_t.intersection(G)
            cardinality = len(t_intersect_G)
            list_cardinality.append(cardinality)
            index = index + 1
    
        max_cardinality = max(list_cardinality)
        indices_max_cardinality = []
        index = 0
        while index < len(list_cardinality):
            if list_cardinality[index] == max_cardinality:
                indices_max_cardinality.append(index)
            index = index + 1
    
        if len(indices_max_cardinality) == 1:
            return list_all_relevant_T_G[indices_max_cardinality[0]]
        else:
            ts_with_same_cardinality = []
            for index in indices_max_cardinality:
                ts_with_same_cardinality.append(list_all_relevant_T_G[index])
    
            cardinalities_t = []
            for t in ts_with_same_cardinality:
                cardinality_t = len(self.all_t[t[0]][t[1]])
                cardinalities_t.append(cardinality_t)
    
            min_cardinality = min(cardinalities_t)
            indices_min_cardinality = []
            index = 0
            while index < len(cardinalities_t):
                if cardinalities_t[index] == min_cardinality:
                    indices_min_cardinality.append(index)
                index = index + 1
    
            if len(indices_min_cardinality) == 1:
                return ts_with_same_cardinality[indices_min_cardinality[0]]
            else:
                return list_all_relevant_T_G[0]

    def lem2(self,lower_or_upper_set):
        conclusion = {}
        for decision in lower_or_upper_set:
            conclusion[decision] = []
            B = lower_or_upper_set[decision]
            G = copy.deepcopy(B)
            Covering_hollow_T = set()
    
            count = 0
            while (len(G) != 0):
                condition_T = set()
                all_relevant_T_G = self.calculate_all_relevant_T_G(G)  # set contains t
                # print("all_relevant_T_G: ", all_relevant_T_G)
    
                T_belongs_to_B = self.get_all_item_in_T(condition_T).issubset(B)
    
                while len(all_relevant_T_G) != 0 and (len(condition_T) == 0 or (not T_belongs_to_B)):  # while T = Ø or [T] Õ/ B
                    t = self.select_a_t(all_relevant_T_G, G)
                    all_relevant_T_G.remove(t)
                    # print("condition_T 1: ", condition_T)
                    # print("t 1: ", t)
                    temp = set()
                    temp.add(tuple(t))
                    condition_T = condition_T.union(temp)
                    G = G.intersection(self.all_t[t[0]][t[1]])  # G := [t] « G;
                    all_relevant_T_G = self.calculate_all_relevant_T_G(G)
                    all_relevant_T_G = all_relevant_T_G.difference(condition_T)  # T(G) := T(G) – T;
                    T_belongs_to_B = self.get_all_item_in_T(condition_T).issubset(B)
                # end inner while
    
                # if len(condition_T) == 1:
                #     print("condition_T: ", condition_T, " count: ", count)
                #     break
                # for each t in T do
                #set_t_to_delete_from_condition_T = []
                copy_ = condition_T.copy()
                for t in copy_:
                    # print("condition_T 1: ", condition_T)
                    copy_T = copy.deepcopy(condition_T)
                    # print("copy 1: ", copy_T)
                    # print("t 1: ", t)
                    self.delete_t_from_T(copy_T, t)
                    # print("copy 2: ", copy_T)    
                    if copy_T != None and len(copy_T) != 0:
                        all_items_in_remove_t = self.get_all_item_in_T(copy_T)
                        if all_items_in_remove_t.issubset(B):                       
                            condition_T = copy_T
#                if len(set_t_to_delete_from_condition_T) != 0:
#                    # print("set_t_to_delete_from_condition_T: ", set_t_to_delete_from_condition_T)
#                    list_condition_T = list(condition_T)
#                    # print("list_condition_T: before", list_condition_T)
#                    for t in set_t_to_delete_from_condition_T:
#                        index = 0
#                        while index < len(list_condition_T):
#                            if list_condition_T[index][0] == t[0] and list_condition_T[index][1] == t[1]:
#                                list_condition_T.pop(index)
#                            else:
#                                index = index + 1
#                    condition_T = set(list_condition_T)
                    # print("condition_T: after", condition_T)
                # end: for each t in T do
    
                # print("Covering_hollow_T, before union: ", Covering_hollow_T)
                # print("condition_T: ", condition_T)
                temp = set()
                temp.add(tuple(condition_T))
                Covering_hollow_T = Covering_hollow_T.union(temp)
                # print("Covering_hollow_T, after union: ", Covering_hollow_T)
    
                # print("B1: ", B)
                # print("get_all_item_in_hollow_T(Covering_hollow_T): ", get_all_item_in_hollow_T(Covering_hollow_T))
                G = B.difference(self.get_all_item_in_hollow_T(Covering_hollow_T))
                # print("G1: after", G)
                count = count + 1
            # outer while
            copy_ = Covering_hollow_T.copy()
            for T in copy_:
                # print("Covering_hollow_T: ", Covering_hollow_T)
                # print("T: ", T)
                hollowT_minus_T = self.delete_T_from_hollow_T(Covering_hollow_T, T)
                # print("hollowT_minus_T: ", hollowT_minus_T)
    
                all_item_in_hollowT_minus_T = self.get_all_item_in_hollow_T(hollowT_minus_T)
                list_all_item_in_hollowT_minus_T = list(all_item_in_hollowT_minus_T)
                list_all_item_in_hollowT_minus_T.sort()
                list_B = list(B)
                list_B.sort()
    
                # print("list_all_item_in_hollowT_minus_T: ", list_all_item_in_hollowT_minus_T)
                # print("list_B: ", list_B)
                if list_all_item_in_hollowT_minus_T == list_B:
                    # print("Covering_hollow_T 1: ", Covering_hollow_T)
                     Covering_hollow_T.remove(T)
            conclusion[decision] = Covering_hollow_T
        return conclusion

