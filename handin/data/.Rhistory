if(u[i] < probs[1]){
u[i] <- x[i]
}
else{
for(j in 2:length(probs)){
if(sum(probs[1:(j-1)]) <= u[i] && u[i] < sum(probs[1:j])){
u[i] <- x[i]
}
else if(sum(probs[1:j]) == 1){
u[i] <- x[i]
}
}
}
}
}
x <- c(1,2,5)
sample <- random(100,x, x/8)
random <- function(n,x,probs){
u <- runif(n)
for(i in 1:length(u)){
if(u[i] < probs[1]){
u[i] <- x[i]
}
else{
for(j in 2:length(probs)){
if(sum(probs[1:(j-1)]) <= u[i] && u[i] < sum(probs[1:j])){
u[i] <- x[i]
}
else if(sum(probs[1:j]) == 1){
u[i] <- x[i]
}
}
}
}
}
x <- c(1,2,5)
sample <- random(100,x, x/8)
source('~/.active-rstudio-document', echo=TRUE)
sample <- random(100,x, probs)
sample <- random(100,x, probs)
probs <- c(1/8,2/8,5/8)
random <- function(n,x,probs){
u <- runif(n)
for(i in 1:length(u)){
if(u[i] < probs[1]){
u[i] <- x[i]
}
else{
for(j in 2:length(probs)){
if(sum(probs[1:(j-1)]) <= u[i] && u[i] < sum(probs[1:j])){
u[i] <- x[j]
}
}
}
}
}
x <- c(1,2,5)
sample <- random(100,x, probs)
probs <- c(1/8,2/8,5/8)
random <- function(n,x,probs){
u <- runif(n)
for(i in 1:length(u)){
if(u[i] < probs[1]){
u[i] <- x[i]
}
else{
for(j in 2:length(probs)){
if(sum(probs[1:(j-1)]) <= u[i] && u[i] < sum(probs[1:j])){
u[i] <- x[j]
}
}
}
}
}
x <- c(1,2,5)
sample <- random(100,x, probs)
probs <- c(1/8,2/8,5/8)
random <- function(n,x,probs){
u <- runif(n)
for(i in 1:length(u)){
if(u[i] < probs[1]){
u[i] <- x[i]
}
else{
for(j in 2:length(probs)){
if(sum(probs[1:(j-1)]) <= u[i] && u[i] < sum(probs[1:j])){
u[i] <- x[j]
}
}
}
}
return (u)
}
x <- c(1,2,5)
sample <- random(100,x, probs)
hist(sample)
probs <- c(1/8,2/8,5/8)
random <- function(n,x,probs){
u <- runif(n)
for(i in 1:length(u)){
if(u[i] < probs[1]){
u[i] <- x[1]
}
else{
for(j in 2:length(probs)){
if(sum(probs[1:(j-1)]) <= u[i] && u[i] < sum(probs[1:j])){
u[i] <- x[j]
}
}
}
}
return (u)
}
x <- c(1,2,5)
sample <- random(100,x, probs)
hist(sample)
1 >= 0
mean(1>0)
x <- c(1,2,3,45,6,6)
mean(x>0)
x <- c(1,2,3,45,6,6)
x <- c(1,2,3,4,5,6,7)
mean(x>1)
x <- c(1,2,3,4,5,6,7)
mean(x>1)
mean(x>1)
sum(x>=1)
x <- c(1,2,3,4,5,6,7)
mean(x>1)
sum(x>=1)
hist(x)
x <- runif(10000)
hist(x)
x1 <- x[-10000]
x2 <- x[-1]
hyperplane.data = hyperplane(10000, 20, 5, 1.0, .05, .1)
hyperplane = function(num.to.generate, num.attributes, num.with.drift, mag.of.change, noise, prob.direction.change) {
static.weights = runif(num.attributes - num.with.drift)
static.weightz = do.call(rbind, lapply(1:num.to.generate, function(x) { static.weights}))
dynamic.weights = do.call(cbind, lapply(runif(num.with.drift), function(start) { drift(start, num.to.generate, mag.of.change, prob.direction.change)}))
weights = cbind(dynamic.weights, static.weightz)
data = matrix(ncol=num.attributes, nrow=num.to.generate, runif(num.attributes * num.to.generate))
data = as.data.frame(data)
a.zero = apply(weights, 1, function(x) { .5*sum(x) })
classes = apply(data * weights, 1, sum)  < a.zero
# Do everything and then add noise
c = sapply(classes, function(class) { if (runif(1) <= noise) { !class } else class })
data$response = sapply(c, function(boo) { if(boo) {"class1"} else { "class2"}})
list(data=data, weights=weights)
}
# This will generate 15 different datasets of 10000 observations
set.seed(1)
for (i in 1:15) {
hyperplane.data = hyperplane(10000, 20, 5, 1.0, .05, .1)
write.csv(hyperplane.data$data, paste("hyperplane", i, ".csv", sep=""), row.names=FALSE)
write.csv(hyperplane.data$weights, paste("weights", i, ".csv", sep=""), row.names=FALSE)
}
drift = function(start, numberToGenerate, magnitudeOfChange, probDirectionChange) {
directions = rep(magnitudeOfChange, numberToGenerate - 1)
for (i in 2:(numberToGenerate-1)) {
if(!(runif(1) >= probDirectionChange)) {
directions[i] = (directions[i-1] * -1)
} else {
directions[i] = (directions[i-1])
}
}
builder = c(start)
for (direction in directions) {
start = start + direction
builder = c(builder, start)
}
builder
}
hyperplane = function(num.to.generate, num.attributes, num.with.drift, mag.of.change, noise, prob.direction.change) {
static.weights = runif(num.attributes - num.with.drift)
static.weightz = do.call(rbind, lapply(1:num.to.generate, function(x) { static.weights}))
dynamic.weights = do.call(cbind, lapply(runif(num.with.drift), function(start) { drift(start, num.to.generate, mag.of.change, prob.direction.change)}))
weights = cbind(dynamic.weights, static.weightz)
data = matrix(ncol=num.attributes, nrow=num.to.generate, runif(num.attributes * num.to.generate))
data = as.data.frame(data)
a.zero = apply(weights, 1, function(x) { .5*sum(x) })
classes = apply(data * weights, 1, sum)  < a.zero
# Do everything and then add noise
c = sapply(classes, function(class) { if (runif(1) <= noise) { !class } else class })
data$response = sapply(c, function(boo) { if(boo) {"class1"} else { "class2"}})
list(data=data, weights=weights)
}
# This will generate 15 different datasets of 10000 observations
set.seed(1)
for (i in 1:15) {
hyperplane.data = hyperplane(10000, 20, 5, 1.0, .05, .1)
write.csv(hyperplane.data$data, paste("hyperplane", i, ".csv", sep=""), row.names=FALSE)
write.csv(hyperplane.data$weights, paste("weights", i, ".csv", sep=""), row.names=FALSE)
}
hyperplane.data = hyperplane(10000, 10, 5, 1.0, .05, .1)
# This will generate 15 different datasets of 10000 observations
set.seed(1)
hyperplane.data = hyperplane(10000, 10, 5, 1.0, .05, .1)
write.csv(hyperplane.data$data, paste("hyperplane", i, ".csv", sep=""), row.names=FALSE)
# This will generate 15 different datasets of 10000 observations
set.seed(1)
hyperplane.data = hyperplane(10000, 20, 5, 1.0, .05, .1)
write.csv(hyperplane.data$data, paste("hyperplane", i, ".csv", sep=""), row.names=FALSE)
drift = function(start, numberToGenerate, magnitudeOfChange, probDirectionChange) {
directions = rep(magnitudeOfChange, numberToGenerate - 1)
for (i in 2:(numberToGenerate-1)) {
if(!(runif(1) >= probDirectionChange)) {
directions[i] = (directions[i-1] * -1)
} else {
directions[i] = (directions[i-1])
}
}
builder = c(start)
for (direction in directions) {
start = start + direction
builder = c(builder, start)
}
builder
}
hyperplane = function(num.to.generate, num.attributes, num.with.drift, mag.of.change, noise, prob.direction.change) {
static.weights = runif(num.attributes - num.with.drift)
static.weightz = do.call(rbind, lapply(1:num.to.generate, function(x) { static.weights}))
dynamic.weights = do.call(cbind, lapply(runif(num.with.drift), function(start) { drift(start, num.to.generate, mag.of.change, prob.direction.change)}))
weights = cbind(dynamic.weights, static.weightz)
data = matrix(ncol=num.attributes, nrow=num.to.generate, runif(num.attributes * num.to.generate))
data = as.data.frame(data)
a.zero = apply(weights, 1, function(x) { .5*sum(x) })
classes = apply(data * weights, 1, sum)  < a.zero
# Do everything and then add noise
c = sapply(classes, function(class) { if (runif(1) <= noise) { !class } else class })
data$response = sapply(c, function(boo) { if(boo) {"class1"} else { "class2"}})
list(data=data, weights=weights)
}
# This will generate 15 different datasets of 10000 observations
set.seed(1)
hyperplane.data = hyperplane(10000, 20, 5, 1.0, .05, .1)
write.csv(hyperplane.data$data, paste("hyperplane", 20, ".csv", sep=""), row.names=FALSE)
# This will generate 15 different datasets of 10000 observations
set.seed(1)
hyperplane.data = hyperplane(10000, 20, 5, 1.0, .05, .1)
write.csv(hyperplane.data$data, paste("hyperplane", 15, ".csv", sep=""), row.names=FALSE)
# This will generate 15 different datasets of 10000 observations
set.seed(1)
hyperplane.data = hyperplane(10000, 30, 5, 1.0, .05, .1)
write.csv(hyperplane.data$data, paste("hyperplane", 30, ".csv", sep=""), row.names=FALSE)
df = read.csv('movingRBF.csv')
df = data.frame(df)
setwd("C:/Users/needon/Desktop/4710 research/source code/item-based-collaborative-filtering/crispRoughSetCode/data")
library(RoughSets)
df = read.csv('movingRBF.csv')
df = data.frame(df)
decision.table <- SF.asDecisionTable(dataset = df, decision.attr = 10)
cut.values <- D.discretization.RST(decision.table, nOfIntervals = 10)
View(cut.values)
View(cut.values)
d.m <- SF.applyDecTable(decision.table, cut.values)
library(RoughSets)
df = read.csv('movingRBF.csv')
df = data.frame(df)
decision.table <- SF.asDecisionTable(dataset = df, decision.attr = 10)
cut.values <- D.discretization.RST(decision.table, nOfIntervals = 10)
decision.table <- SF.applyDecTable(decision.table, cut.values)
attr.P <- c(1,2,3)
IND <- BC.IND.relation.RST(df,feature.set = attr.P)
IND <- BC.IND.relation.RST(decision.table,feature.set = attr.P)
View(IND)
View(IND)
decision.table[0]
View(decision.table)
View(decision.table)
View(decision.table)[0][1]
View(decision.table)[0][2]
View(decision.table)[1]
View(decision.table)[0,0]
decision.table[0,0]
decision.table[0,1]
decision.table[0]
decision.table[1]
decision.table[11]
decision.table[12]
decision.table[10]
decision.table[1]
library(RoughSets)
df = discretizeDF(read.csv('movingRBF.csv'), include.lowest = TRUE, breaks = 3)
install.packages("arules")
library(RoughSets)
library(arules)
df = discretizeDF(read.csv('movingRBF.csv'), include.lowest = TRUE, breaks = 10, methods = "cluster")
library(arules)
df = discretizeDF(read.csv('movingRBF.csv'), methods = "cluster")
df = discretizeDF(read.csv('movingRBF.csv'))
View(df)
View(df)
View(df)
View(df)
library(RoughSets)
library(arules)
df = discretizeDF(read.csv('movingRBF.csv'), breaks = list(range(10)))
library(arules)
df = discretizeDF(read.csv('movingRBF.csv'), breaks = 10, labels = c("target"))
df = discretizeDF(read.csv('movingRBF.csv'), default = list(breaks = 10, labels = c("target")))
View(df)
View(df)
df = discretizeDF(read.csv('movingRBF.csv'), default = list(method = "cluster", breaks = 10, labels = c("target")))
View(df)
View(df)
View(df)
df = discretizeDF(read.csv('movingRBF.csv')[,0:10], default = list(method = "cluster", breaks = 10,include.lowest = TRUE))
View(df)
df = discretizeDF(read.csv('movingRBF.csv')[,0:11], default = list(method = "cluster", breaks = 10,include.lowest = TRUE))
View(df)
View(df)
df = discretizeDF(read.csv('movingRBF.csv')[,0:9], default = list(method = "cluster", breaks = 10,include.lowest = TRUE))
View(df)
View(df)
df = discretizeDF(read.csv('movingRBF.csv')[,0:10], default = list(method = "cluster", breaks = 10,include.lowest = TRUE))
df = cbind(df,read.csv('movingRBF.csv')[,10])
X = df[0:2000,0:10]
Y = df[0:2000,10]
decision.table <- SF.asDecisionTable(dataset = df[0:2000,], decision.attr = 10)
rule = RI.LEM2Rules.RST(decision.table)
View(decision.table)
df <- sapply(df,as.character)
View(df)
View(df)
View(df)
View(df)
View(df)
df = discretizeDF(read.csv('movingRBF.csv')[,0:10], default = list(method = "cluster", breaks = 10,include.lowest = TRUE))
df = cbind(df,read.csv('movingRBF.csv')[,10])
View(df)
df = cbind(df,read.csv('movingRBF.csv')[,11])
View(df)
View(df)
df = discretizeDF(read.csv('movingRBF.csv')[,0:10], default = list(method = "cluster", breaks = 10,include.lowest = TRUE))
df = cbind(df,read.csv('movingRBF.csv')[,11])
View(df)
View(df)
df = discretizeDF(read.csv('movingRBF.csv')[,0:10], default = list(method = "cluster", breaks = 10,include.lowest = TRUE))
target = read.csv('movingRBF.csv')[,11]
df = cbind(df,target)
View(df)
View(df)
#df <- sapply(df,as.character)
decision.table <- SF.asDecisionTable(dataset = df[0:2000,], decision.attr = 10)
rule = RI.LEM2Rules.RST(decision.table)
df <- sapply(df,as.character)
decision.table <- SF.asDecisionTable(dataset = df[0:2000,], decision.attr = 10)
decision.table <- SF.asDecisionTable(dataset = df[0:2000,], decision.attr = 11)
rule = RI.LEM2Rules.RST(decision.table)
View(decision.table)
target = sapply(read.csv('movingRBF.csv')[,11],as.character)
df = cbind(df,target)
df = discretizeDF(read.csv('movingRBF.csv')[,0:10], default = list(method = "cluster", breaks = 10,include.lowest = TRUE))
target = sapply(read.csv('movingRBF.csv')[,11],as.character)
df = cbind(df,target)
decision.table <- SF.asDecisionTable(dataset = df[0:2000,], decision.attr = 11)
rule = RI.LEM2Rules.RST(decision.table)
View(rule)
View(rule)
predict.RuleSetRST(df[2001,0:10])
rule.predict.RuleSetRST(df[2001,0:10])
predict.RuleSetRST(rule,df[2001,0:10])
predict(rule,df[2001,0:10])
red.rst <- FS.feature.subset.computation(decision.table,method="quickreduct.rst")
predict(rule,SF.asDecisionTable(dataset = df[2001:2200,], decision.attr = 11))
df = discretizeDF(read.csv('movingRBF.csv')[,0:10], default = list(method = "cluster", breaks = 10,include.lowest = TRUE))
target = sapply(read.csv('movingRBF.csv')[,11],as.character)
df = cbind(df,target)
decision.table <- SF.asDecisionTable(dataset = df[0:2000,], decision.attr = 11)
red.rst <- FS.feature.subset.computation(decision.table,method="quickreduct.rst")
rules <- RI.indiscernibilityBasedRules.RST(decision.table,red.rst)
test = SF.asDecisionTable(dataset = df[2001:2200,], decision.attr = 11)
predict(rule,test)
pred = predict(rule,test)
real = target[2001:2200,]
real = target[2001:2200]
View(pred)
View(pred)
pred == real
View(rule)
rules <- RI.LEM2Rules.RST(decision.table,red.rst)
rules <- RI.LEM2Rules.RST(decision.table)
View(rule)
View(rule)
View(rules)
View(rules)
test = SF.asDecisionTable(dataset = df[2001:2200,], decision.attr = 11)
pred = predict(rule,test)
real = target[2001:2200]
pred == real
sum(pred == real)
library(RoughSets)
library(arules)
df = discretizeDF(read.csv('movingRBF.csv')[,0:10], default = list(method = "cluster", breaks = 10,include.lowest = TRUE))
target = sapply(read.csv('movingRBF.csv')[,11],as.character)
df = cbind(df,target)
correct = 0
while (i < 200000){
decision.table <- SF.asDecisionTable(dataset = df[0:i,], decision.attr = 11)
red.rst <- FS.feature.subset.computation(decision.table,method="quickreduct.rst")
rules <- RI.LEM2Rules.RST(decision.table)
test = SF.asDecisionTable(dataset = df[i+1,], decision.attr = 11)
pred = predict(rule,test)
real = target[i+1]
correct = correct + sum(pred == real)
i = i + 1
}
i = 2000
correct = 0
while (i < 200000){
decision.table <- SF.asDecisionTable(dataset = df[0:i,], decision.attr = 11)
red.rst <- FS.feature.subset.computation(decision.table,method="quickreduct.rst")
rules <- RI.LEM2Rules.RST(decision.table)
test = SF.asDecisionTable(dataset = df[i+1,], decision.attr = 11)
pred = predict(rule,test)
real = target[i+1]
correct = correct + sum(pred == real)
i = i + 1
}
rules <- RI.indiscernibilityBasedRules.RST(decision.table,red.rst)
library(RoughSets)
library(arules)
df = discretizeDF(read.csv('movingRBF.csv')[,0:10], default = list(method = "cluster", breaks = 10,include.lowest = TRUE))
library(RoughSets)
library(arules)
df = discretizeDF(read.csv('movingRBF.csv')[,0:10], default = list(method = "cluster", breaks = 10,include.lowest = TRUE))
target = sapply(read.csv('movingRBF.csv')[,11],as.character)
df = cbind(df,target)
i = 2000
library(RoughSets)
library(arules)
df = discretizeDF(read.csv('movingRBF.csv')[,0:10], default = list(method = "cluster", breaks = 10,include.lowest = TRUE))
target = sapply(read.csv('movingRBF.csv')[,11],as.character)
df = cbind(df,target)
i = 2000
correct = 0
while (i < 200000){
decision.table <- SF.asDecisionTable(dataset = df[0:i,], decision.attr = 11)
red.rst <- FS.feature.subset.computation(decision.table,method="quickreduct.rst")
rules <- RI.indiscernibilityBasedRules.RST(decision.table,red.rst)
test = SF.asDecisionTable(dataset = df[i+1,], decision.attr = 11)
pred = predict(rule,test)
real = target[i+1]
correct = correct + sum(pred == real)
i = i + 1
}
while (i < 200000){
decision.table <- SF.asDecisionTable(dataset = df[0:i,], decision.attr = 11)
red.rst <- FS.feature.subset.computation(decision.table,method="quickreduct.rst")
rules <- RI.indiscernibilityBasedRules.RST(decision.table,red.rst)
test = SF.asDecisionTable(dataset = df[i+1,], decision.attr = 11)
pred = predict(rules,test)
real = target[i+1]
correct = correct + sum(pred == real)
i = i + 1
}
i = 2000
correct = 0
while (i < 200000){
decision.table <- SF.asDecisionTable(dataset = df[0:i,], decision.attr = 11)
red.rst <- FS.feature.subset.computation(decision.table,method="quickreduct.rst")
rules <- RI.indiscernibilityBasedRules.RST(decision.table,red.rst)
test = SF.asDecisionTable(dataset = df[i+1,], decision.attr = 11)
pred = predict(rules,test)
real = target[i+1]
correct = correct + sum(pred == real)
i = i + 1
}
i = 2000
correct = 0
while (i < 200000){
decision.table <- SF.asDecisionTable(dataset = df[0:i,], decision.attr = 11)
red.rst <- FS.feature.subset.computation(decision.table,method="quickreduct.rst")
rules <- RI.indiscernibilityBasedRules.RST(decision.table,red.rst)
test = SF.asDecisionTable(dataset = df[i+1,], decision.attr = 11)
pred = predict(rules,test)
real = target[i+1]
correct = correct + sum(pred == real)
i = i + 1
}
library(RoughSets)
library(arules)
df = discretizeDF(read.csv('movingRBF.csv')[,0:10], default = list(method = "cluster", breaks = 10,include.lowest = TRUE))
target = sapply(read.csv('movingRBF.csv')[,11],as.character)
df = cbind(df,target)
i = 2000
correct = 0
while (i < 200000){
decision.table <- SF.asDecisionTable(dataset = df[0:i,], decision.attr = 11)
red.rst <- FS.feature.subset.computation(decision.table,method="quickreduct.rst")
rules <- RI.indiscernibilityBasedRules.RST(decision.table,red.rst)
test = SF.asDecisionTable(dataset = df[i+1,], decision.attr = 11)
pred = predict(rules,test)
real = target[i+1]
correct = correct + sum(pred == real)
i = i + 1
}
i = 2000
correct = 0
while (i < 200000){
decision.table <- SF.asDecisionTable(dataset = df[0:i,], decision.attr = 11)
red.rst <- FS.feature.subset.computation(decision.table,method="quickreduct.rst")
rules <- RI.indiscernibilityBasedRules.RST(decision.table,red.rst)
test = SF.asDecisionTable(dataset = df[i+1,], decision.attr = 11)
pred = predict(rules,test)
real = target[i+1]
correct = correct + sum(pred == real)
i = i + 1
}
View(rules)
View(rules)
